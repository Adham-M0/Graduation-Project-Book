\textbf{\large Abstract}\\

This project addresses the challenge of accessibility for visually impaired individuals by focusing on the translation of Braille text into both printed text and speech. With millions of visually impaired individuals relying on Braille, there is a significant need for technology that bridges the gap between Braille literacy and digital accessibility. The primary objective of this project is to develop an inexpensive system that requires minimal user interaction, accurately translating scanned single-sided Braille pages into printed text and subsequently converting the text into speech. The project employs a dual-method approach for Optical Braille Recognition (OBR): the first using image processing techniques, and the second utilizing a Convolutional Neural Network (CNN). The process begins with the preprocessing of Braille pages, followed by the detection of Braille symbols through image processing techniques. These symbols are then recognized using both methods and converted into corresponding printed text. Finally, text-to-speech technology is used to convert the printed text into natural-sounding speech output. The developed system demonstrates high accuracy in translating Braille to text.  Our OBR system not only provides high accuracy but also ensures reliability, efficiency, and affordability. Additionally, we introduce a new Braille dataset containing annotated images of Braille symbols. This project successfully creates a robust tool for translating Braille into text and speech, significantly improving accessibility for the visually impaired community. The system facilitates easier access to written content and promotes greater independence and inclusion. Future enhancements could focus on expanding language support and integrating the system with mobile devices. \\
\\ \textbf{Keywords:} Optical Braille Recognition (OBR), Image processing, Convolutional Neural Network (CNN), text-to-speech, Braille Dataset.

